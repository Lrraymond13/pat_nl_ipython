{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "from keras import backend as K\n",
    "import keras.layers as layers\n",
    "from keras.models import Model, load_model\n",
    "from keras.engine import Layer\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import string\n",
    "# Initialize session\n",
    "#sess = tf.Session()\n",
    "#K.set_session(sess)\n",
    "\n",
    "\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "\n",
    "# # can't run a gpu on here, would need to build against the sched_mit_sloan_gpu\n",
    "# #with tf.device('/cpu:0'):\n",
    "# a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "# b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "# c = tf.matmul(a, b)\n",
    "\n",
    "# # Creates a session with log_device_placement set to True.\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v6 = pd.read_pickle(\n",
    "    '/pool001/lraymond/processed_data/pre_analysis_dfs/standardized_linear_classifier_df.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and add back in text classification\n",
    "def load_zipped_pickle(filename):\n",
    "    # load a zipped compressed pickle file\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object\n",
    "    \n",
    "index_file = '/pool001/lraymond/patent_data/index_files/sample_pat_nums_all_numerical.gzip'\n",
    "\n",
    "valid_patents2 = load_zipped_pickle(index_file)\n",
    "\n",
    "valid_patents2 = valid_patents2.set_index('patent_number')\n",
    "\n",
    "# here is where I would add in additional pieces of textual data if I wanted\n",
    "\n",
    "v7 = pd.merge(\n",
    "    v6, valid_patents2[['patent_abstract', 'patent_title']], left_index=True, right_index=True, how='inner')\n",
    "\n",
    "\n",
    "\n",
    "print(v6.shape)\n",
    "print(v7.shape)\n",
    "\n",
    "v8_text = v7.loc[v7.missing_patent_abstract==0, :]\n",
    "print(v8_text.shape)\n",
    "\n",
    "del valid_patents2, v6, v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     dataset = tf.keras.utils.get_file(\n",
    "#       fname=\"aclImdb.tar.gz\", \n",
    "#       origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
    "#       extract=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmoEmbeddingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dimensions = 1024\n",
    "        self.trainable = True\n",
    "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
    "\n",
    "def build(self, input_shape):\n",
    "        self.elmo = hub.Module(\n",
    "            'https://tfhub.dev/google/elmo/2', trainable=self.trainable, name=\"{}_module\".format(self.name))\n",
    "        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
    "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "def call(self, x, mask=None):\n",
    "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
    "                      as_dict=True,\n",
    "                      signature='default',\n",
    "                      )['default']\n",
    "        return result\n",
    "\n",
    "def compute_mask(self, inputs, mask=None):\n",
    "        return K.not_equal(inputs, '--PAD--')\n",
    "\n",
    "def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build model\n",
    "def build_model(): \n",
    "    input_text = layers.Input(shape=(1,), dtype=\"string\")\n",
    "    embedding = ElmoEmbeddingLayer()(input_text)\n",
    "    dense = layers.Dense(256, activation='relu')(embedding)\n",
    "    pred = layers.Dense(1, activation='sigmoid')(dense)\n",
    "    model = Model(inputs=[input_text], outputs=pred)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_abstract(abstract_str):\n",
    "    # remove punctuation from each word\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    try:\n",
    "        str2 = abstract_str.strip()\n",
    "        return ' '.join(w.translate(table) for w in str2.split() if w.isalpha())\n",
    "    except AttributeError as e:\n",
    "        print(e, abstract_str)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to remove punctuation from abstracts\n",
    "\n",
    "v8_text['patent_abstract'] = v8_text['patent_abstract'].apply(clean_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v8_text.loc[pd.isnull(v8_text.patent_abstract), 'missing_patent_abstract'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v8_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data should be a dataframe of sentences and target value\n",
    "text_cols = ['patent_abstract']\n",
    "Y_col = ['10_year_cites_top1']\n",
    "model_df = v8_text.loc[v8_text['missing_patent_abstract']==0, text_cols + Y_col].copy()\n",
    "\n",
    "# 1:1 ratio of top 1 and not\n",
    "rus = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=1, return_indices=True, random_state=0)\n",
    "\n",
    "X = model_df[text_cols].as_matrix()\n",
    "Y = model_df[Y_col].as_matrix()\n",
    "# (X[ind]==X_resampled).all() should be True\n",
    "X_resampled, y_resampled, ind = rus.fit_resample(X, Y)\n",
    "print(X_resampled.shape, y_resampled.shape, y_resampled.mean())\n",
    "    \n",
    "X_train, X_test, y_train, y_test, pat_nums_train, pat_nums_test = sklearn.model_selection.train_test_split(\n",
    "    X_resampled, y_resampled, ind, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = model_df['patent_abstract'].tolist()\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and fit\n",
    "model = build_model()\n",
    "model.fit(X_train, \n",
    "          y_train,\n",
    "          validation_data=(X_test, y_test),\n",
    "          epochs=5,\n",
    "          batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ElmoModel.h5')\n",
    "pre_save_preds = model.predict(test_text[0:100]) # predictions before we clear and reload model\n",
    "\n",
    "# Clear and load model\n",
    "model = None\n",
    "model = build_model()\n",
    "model.load_weights('ElmoModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart and reload so can use pre trained elmo embeddings, weakly train classifier on patent abstract and title\n",
    "# then estimate model accuracy.\n",
    "# save embeddings in numpy and then load them into tensor scratch for model building\n",
    "# then, write a script that generates output for a variety of combos of NNs and SVMs with and without text classification\n",
    "# next step is to try to train embeddings from scratch\n",
    "# then switch output to a different function\n",
    "# write down a list of questions to answer for meeting on Friday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=False)\n",
    "embeddings = elmo(\n",
    "    [\"the cat is on the mat\", \"what are you doing in evening\"],signature=\"default\",\n",
    "    as_dict=True)[\"elmo\"]\n",
    "with tf.Session() as session:\n",
    "    tf.initialize_all_variables.run()\n",
    "    tf.tables_initializer().run()\n",
    "    #session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    message_embeddings = session.run(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/software/sloan/local/lib/py36/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-37e872c55f81>\", line 1, in <module>\n",
      "    message_embeddings\n",
      "NameError: name 'message_embeddings' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/software/sloan/local/lib/py36/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/software/sloan/local/lib/py36/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/software/sloan/local/lib/py36/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/software/sloan/local/lib/py36/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/software/python/3.6.3/lib/python3.6/inspect.py\", line 1480, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/software/python/3.6.3/lib/python3.6/inspect.py\", line 1438, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/software/python/3.6.3/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/software/python/3.6.3/lib/python3.6/inspect.py\", line 730, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/lraymond/.local/lib/python3.6/site-packages/py/_vendored_packages/apipkg.py\", line 195, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"/home/lraymond/.local/lib/python3.6/site-packages/py/_vendored_packages/apipkg.py\", line 179, in getmod\n",
      "    x = importobj(modpath, None)\n",
      "  File \"/home/lraymond/.local/lib/python3.6/site-packages/py/_vendored_packages/apipkg.py\", line 69, in importobj\n",
      "    module = __import__(modpath, None, None, ['__doc__'])\n",
      "  File \"/home/lraymond/.local/lib/python3.6/site-packages/pytest.py\", line 14, in <module>\n",
      "    from _pytest.fixtures import fillfixtures as _fillfuncargs\n",
      "  File \"/home/lraymond/.local/lib/python3.6/site-packages/_pytest/fixtures.py\", line 19, in <module>\n",
      "    from _pytest import nodes\n",
      "  File \"/home/lraymond/.local/lib/python3.6/site-packages/_pytest/nodes.py\", line 13, in <module>\n",
      "    from _pytest.mark.structures import NodeKeywords\n",
      "  File \"/home/lraymond/.local/lib/python3.6/site-packages/_pytest/mark/__init__.py\", line 8, in <module>\n",
      "    from .structures import EMPTY_PARAMETERSET_OPTION\n",
      "  File \"/home/lraymond/.local/lib/python3.6/site-packages/_pytest/mark/structures.py\", line 141, in <module>\n",
      "    class Mark(object):\n",
      "  File \"/home/lraymond/.local/lib/python3.6/site-packages/_pytest/mark/structures.py\", line 143, in Mark\n",
      "    name = attr.ib(type=str)\n",
      "TypeError: attr() got an unexpected keyword argument 'type'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'message_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "message_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
