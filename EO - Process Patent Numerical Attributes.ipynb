{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Patent Attributes Into a Dataset\n",
    "\n",
    "Note that the Google online patent dataset has a better but more extensive version of this data. If this works, it may make sense to use their data set which includes more detailed information on type of references, and probably a better version of the claims with better priority information. \n",
    "\n",
    "The reason I didn't use this dataset now is that it is much more stuctured because it contains all patents over all time, so much more upfront cost to working with it. The best way to work with it is to find the attributes that are important, have the algorithm chosen and then download the data. \n",
    "\n",
    "Another outcome variable I'd like is patent renewal, but I wasn't able to find that directly from the USPTO website. Looking at the Falk and Train paper, the best data source for this is the \"the “INPADOC Legal Status Code” and the “US Post Issuance” fields in\n",
    "Thomson Innovation’s database, which describes official updates to the status of a patent. The update codes are\n",
    "country-specific, so expired takes on a “1” if the codes “FP”, “FPB1”, “FPB2”, “FPB3”, or “LAPS” are reported in the\n",
    "“INPADOC Legal Status Code” field or if “EXPI” appears in the “US Post Issuance” field. For expiration dates, this\n",
    "variable relies on the “INPADOC Legal Status Date” and the “US Post Issuance” fields in Thomson Innovation’s\n",
    "database. Date information from the “US Post Issuance” field takes precedence if there is a discrepancy between\n",
    "the two fields. This is because the “US Post-Issuance” field reflects data from the USPTO, updated weekly. See:\n",
    "http://www.thomsoninnovation.com/tip-innovation/support/help/patent_fields.htm#inpadoc_legal_status ;\n",
    "http://www.thomsoninnovation.com/tip-innovation/support/help/legalstatus_codes/lsc_us.htm;\n",
    "http://www.thomsoninnovation.com/tip-innovation/support/help/patent_fields.htm#post_issuance\"\n",
    "Tjos quote is take from footnote 12 on page 5 of patent valuation with forecasts of forward citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additions to the Dataset\n",
    "* add in inventor age\n",
    "    * maybe add in the inventor age at the patent invention data using the inventor or assignee dataset\n",
    "* clean lawyer organization and use that as a categorical\n",
    "\n",
    "## Dataset Problems\n",
    "* some patents that should have citations made are missing them - I have flagged these as missing\n",
    "* some assignment types are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent\n",
    "import pickle\n",
    "import json\n",
    "import funcy\n",
    "import csv\n",
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split description directory\n",
    "patents_dataset_dir = '/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips'\n",
    "patents_dfs_dir = '/nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes'\n",
    "\n",
    "# I should be story these files in the lustre parallel file system\n",
    "\n",
    "# I want to stripe this directory over 20 servers to optimize performance \n",
    "# /nobackup1/lraymond/patent_data/numerical_patents_datasets\n",
    "# contains gzip files patents_year_1979.gz to patents_year_2013.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_large_pickle_file(df, filepath):\n",
    "    max_bytes = 2 ** 31 - 1\n",
    "    with open(filepath, 'wb') as f:\n",
    "        bytes_out = pickle.dumps(df)\n",
    "        for idx in range(0, len(bytes_out), max_bytes):\n",
    "            f.write(bytes_out[idx:idx + max_bytes])\n",
    "\n",
    "\n",
    "def read_large_pickle_file(filepath):\n",
    "    max_bytes = 2 ** 31 - 1\n",
    "    bytes_in = bytearray(0)\n",
    "    input_size = os.path.getsize(filepath)\n",
    "    with open(filepath, 'rb') as f_in:\n",
    "        for _ in range(0, input_size, max_bytes):\n",
    "            bytes_in += f_in.read(max_bytes)\n",
    "\n",
    "    data2 = pickle.loads(bytes_in)\n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_decompress_json(year, patents_dir):\n",
    "    jsonfilename = os.path.join(patents_dir, 'patents_year_{}.gz'.format(str(year)))\n",
    "    print(jsonfilename)\n",
    "    with gzip.GzipFile(jsonfilename, 'r') as fin:\n",
    "        data = json.loads(fin.read().decode('utf-8'))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_US_utility_patent(patent_dict):\n",
    "    # filter function for patent sample\n",
    "    if patent_dict['patent_type'] != 'utility':\n",
    "        return False\n",
    "    if patent_dict['patent_firstnamed_inventor_country'] != 'US':\n",
    "        return False\n",
    "    assignee_country = patent_dict['patent_firstnamed_assignee_country']\n",
    "    if assignee_country == 'US' or assignee_country is None:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_select_patents(year, patents_dir=patents_dataset_dir):\n",
    "    # this is a gzipped json file with values data[year] containing year number\n",
    "    # patent_data contains a list of dictionaries each representing a patent\n",
    "    # each item in the list is also a list with the first item being the sequence, the last being a number and the \n",
    "    # middle is the attribute dictionary\n",
    "    # the patent dict is strcutred as a list of lists- each containing 1000 patents - so len(t['patent_data'][x][1]) is 1000\n",
    "    data = read_decompress_json(year, patents_dir)\n",
    "    print(data['year'])\n",
    "    for item in data['patent_data']:\n",
    "        # if a utility patent and US only, yield\n",
    "        _, d, _ = item\n",
    "        for patent_dict in d:\n",
    "            is_sample = is_US_utility_patent(patent_dict)\n",
    "            if is_sample:\n",
    "                yield patent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cites_received(patent_dict, year_range):\n",
    "    yrs = pd.DateOffset(years=year_range)\n",
    "    grant_date = pd.to_datetime(patent_dict['patent_date'], format='%Y-%m-%d', errors='coerce')\n",
    "    max_date = grant_date + yrs\n",
    "    # assuming second item is citation_date\n",
    "    cite_dates = list(map(\n",
    "        lambda x: pd.to_datetime(x[1],format='%Y-%m-%d', errors='coerce'), patent_dict['citations_received']))\n",
    "    return sum(map(lambda x: x <= max_date, cite_dates))\n",
    "   \n",
    "    \n",
    "def is_dict_all_none(input_dict):\n",
    "    # check if dictionary is totally empty\n",
    "    non_null_vals = list(filter(None, input_dict.values()))\n",
    "    return (len(non_null_vals)==0)\n",
    "\n",
    "\n",
    "def filter_null_dicts(list_dicts):\n",
    "    # lots of empty filler values in the dictionary attributes so need to filter these out\n",
    "    _, nonempty = funcy.split(is_dict_all_none, list_dicts)\n",
    "    nonempty = list(nonempty)\n",
    "    if len(nonempty) > 0:\n",
    "        return nonempty\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_forprior_dict(new1, list_dicts):\n",
    "    # when in lack of a better option, select the first attribute\n",
    "    new1['number_forprior'] = len(list_dicts)\n",
    "    new1['forprior_country'] = list_dicts[0]['forprior_country']\n",
    "    new1['forprior_date'] = list_dicts[0]['forprior_date']    \n",
    "    return new1\n",
    "   \n",
    "\n",
    "def process_gov_dict(new1, list_dicts):\n",
    "    new1['number_govint'] = len(list_dicts)\n",
    "    new1['govint_contract_award_number'] = list_dicts[0]['govint_contract_award_number']\n",
    "    return new1\n",
    "\n",
    "\n",
    "def process_app_dict(new1, list_dicts):\n",
    "    new1['number_apps'] = len(list_dicts)\n",
    "    new1['app_number'] = list_dicts[0]['app_number']\n",
    "    new1['app_id'] = list_dicts[0]['app_id']\n",
    "    # app_type 02 through 28 = Utility application\n",
    "    new1['app_type'] = list_dicts[0]['app_type']\n",
    "    new1['app_date'] = list_dicts[0]['app_date']\n",
    "    return new1\n",
    "\n",
    "\n",
    "def process_nber_dict(new1, list_dicts):\n",
    "    new1['number_nbers'] = len(list_dicts)\n",
    "    new1['nber_category_id'] = list_dicts[0]['nber_category_id']\n",
    "    new1['nber_category_title'] = list_dicts[0]['nber_category_title']\n",
    "    new1['nber_subcategory_id'] = list_dicts[0]['nber_subcategory_id']\n",
    "    new1['nber_subcategory_title'] = list_dicts[0]['nber_subcategory_title']\n",
    "    return new1\n",
    "\n",
    "\n",
    "def sort_by_sequence(list_dicts, key_name):\n",
    "    types_list = sorted(list_dicts, key=lambda x: x['{}_sequence'.format(key_name)], reverse=False)\n",
    "    return types_list[0]\n",
    "\n",
    "\n",
    "def convert_assignee_type(assignee_val):\n",
    "    '''\n",
    "    Classification of assignee. 2 - US Company or Corporation, \n",
    "    3 - Foreign Company or Corporation, 4 - US Individual, 5 - Foreign Individual,\n",
    "    6 - US Government, 7 - Foreign Government, 8 - Country Government,\n",
    "    9 - State Government (US). Note: A \"1\" appearing before any of these codes signifies part interest\n",
    "    '''\n",
    "    # returns a string value, rather \n",
    "    if pd.isnull(assignee_val):\n",
    "        return (np.nan, np.nan, np.nan, np.nan)\n",
    "    try:\n",
    "        if assignee_val.startswith('1'):\n",
    "            # if a part interest, categorize that part interest\n",
    "            int_val = int(assignee_val[-1])\n",
    "        else:  \n",
    "            int_val = int(assignee_val)\n",
    "    except ValueError as e:\n",
    "        print(e, assignee_val)\n",
    "        int_val = 10\n",
    "    finally:\n",
    "        ASSIGNEE_DICT = {\n",
    "            2: 'US Company',\n",
    "            3: 'Foreign Company',\n",
    "            4: 'US Individual',\n",
    "            5: 'Foreign Individual',\n",
    "            6: 'US Government',\n",
    "            7: 'Foreign Government',\n",
    "            8: 'US Government',\n",
    "            9: 'US Government',\n",
    "            10: 'Missing'\n",
    "            #add 14\n",
    "        }\n",
    "        # returns assignee string name and then is_company and is_gov flag\n",
    "        mapped_val = ASSIGNEE_DICT.get(int_val, None)\n",
    "        is_company = bool(int_val < 4)\n",
    "        if is_company:\n",
    "            return (mapped_val, int(is_company), 0, 0)\n",
    "        is_gov = bool((int_val > 5) & (int_val < 10))\n",
    "        if is_gov:\n",
    "            return (mapped_val, 0, int(is_gov), 0)\n",
    "        # otherwise and individual\n",
    "        return (mapped_val, 0, 0, bool((int_val < 6) & (int_val > 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_assignee_dict(new1, list_dicts):\n",
    "    new1['number_assignees_sequence'] = max(map(lambda x: x['assignee_sequence'], list_dicts))\n",
    "    new1['number_assignees'] = len(list_dicts)\n",
    "    # sort dictionaries by sequence\n",
    "    first = sort_by_sequence(list_dicts, 'assignee')\n",
    "    raw_assignee = first['assignee_type']\n",
    "    str_val, is_comp, is_gov, is_ind = convert_assignee_type(raw_assignee)\n",
    "    new1['assignee_type'] = str_val\n",
    "    new1['assignee_is_company'] = is_comp\n",
    "    new1['assignee_is_gov'] = is_gov\n",
    "    new1['assignee_is_ind'] = is_ind\n",
    "    new1['assignee_ids']  = list(filter(None, map(lambda x: x['assignee_id'], list_dicts)))\n",
    "    return new1\n",
    "\n",
    "def process_inventor_dict(new1, list_dicts):\n",
    "    first = sort_by_sequence(list_dicts, 'inventor')\n",
    "    new1['inventor_total_num_patents']  = first['inventor_total_num_patents']\n",
    "    new1['number_inventors_sequence'] = max(map(lambda x: x['inventor_sequence'], list_dicts))\n",
    "    new1['number_inventors'] = len(list_dicts)\n",
    "    new1['inventor_ids']  = list(filter(None, map(lambda x: x['inventor_id'], list_dicts)))\n",
    "    return new1\n",
    "\n",
    "def process_lawyers_dict(new1, list_dicts):\n",
    "    first = sort_by_sequence(list_dicts, 'lawyer')\n",
    "    new1['lawyer_total_num_assignees']  = first['lawyer_total_num_assignees']\n",
    "    new1['lawyer_total_num_inventors']  = first['lawyer_total_num_inventors']\n",
    "    new1['lawyer_total_num_patents']  = first['lawyer_total_num_patents']\n",
    "    new1['lawyer_organization']  = first['lawyer_organization']\n",
    "    new1['number_lawyers_sequence'] = max(map(lambda x: x['lawyer_sequence'], list_dicts))\n",
    "    new1['number_lawyers'] = len(list_dicts)\n",
    "    new1['lawyer_ids']  = list(filter(None, map(lambda x: x['lawyer_id'], list_dicts)))\n",
    "    return new1\n",
    "\n",
    "def process_examiners_dict(new1, list_dicts):\n",
    "     # examiners have roles - primary or assistant\n",
    "    new1['number_examiners'] = len(list_dicts)\n",
    "    new1['number_primary_examiners'] = len(list(filter(lambda x: x['examiner_role']=='primary', list_dicts)))\n",
    "    new1['number_assistant_examiners'] = len(list(filter(lambda x: x['examiner_role']=='assistant', list_dicts)))\n",
    "    new1['number_other_examiners'] = len(list(filter(\n",
    "        lambda x: x['examiner_role'] not in ('assistant', 'primary'), list_dicts)))\n",
    "    new1['examiner_ids']  = list(filter(None, map(lambda x: x['examiner_id'], list_dicts)))\n",
    "    return new1\n",
    "\n",
    "\n",
    "def process_cited_dict(new1, list_dicts):\n",
    "    cited_nums = list(map(\n",
    "        lambda x: x['cited_patent_number'], list_dicts))\n",
    "    cited_dates  = list(map(\n",
    "        lambda x: x['cited_patent_date'], list_dicts))\n",
    "    cited_titles = list(map(\n",
    "        lambda x: x['cited_patent_title'], list_dicts)) \n",
    "    new1['citations_made'] = list(zip(cited_nums, cited_dates, cited_titles))\n",
    "    return new1\n",
    "\n",
    "\n",
    "def process_citing_dict(new1, list_dicts):\n",
    "    # these are patents that cite this specific patent in the future\n",
    "    citing_nums = list(map(\n",
    "        lambda x: x['citedby_patent_number'], list_dicts))\n",
    "    citing_dates  = list(map(\n",
    "        lambda x: x['citedby_patent_date'], list_dicts))\n",
    "    # these are 'cited by applicant', 'cited by other', None\n",
    "    citing_cats = list(map(\n",
    "        lambda x: x['citedby_patent_category'], list_dicts))\n",
    "    citing_titles = list(map(\n",
    "        lambda x: x['citedby_patent_title'], list_dicts))\n",
    "   \n",
    "    new1['citations_received'] = list(zip(citing_nums, citing_dates, citing_titles, citing_cats))\n",
    "    new1['20_year_cites'] = count_cites_received(new1, 20)\n",
    "    new1['5_year_cites'] = count_cites_received(new1, 5)\n",
    "    new1['10_year_cites'] = count_cites_received(new1, 10)\n",
    "    new1['15_year_cites'] = count_cites_received(new1, 15)  \n",
    "    new1['30_year_cites'] = count_cites_received(new1, 30)\n",
    "    return new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_patent_dict(raw_dict):\n",
    "    '''\n",
    "    patent type -  Category of patent. There are 6 possible type:\n",
    "    \"Defensive Publication\" - 509, \"Design\" - 474736, \"Plant\" - 21052, \"Reissue\" - 16416, \n",
    "    \"Statutory Invention Registration\" - 2254, \"Utility\" - 4910906.\n",
    "    patent kind - should all be utility\n",
    "    '''\n",
    "    keys_to_keep = (\n",
    "        # patent date is grant date\n",
    "         'patent_abstract', 'patent_date',\n",
    "        # assignee info\n",
    "        'patent_firstnamed_assignee_city',  'patent_firstnamed_assignee_country', \n",
    "        'patent_firstnamed_assignee_id', 'patent_firstnamed_assignee_location_id', \n",
    "        'patent_firstnamed_assignee_state', \n",
    "        # inventor\n",
    "        'patent_firstnamed_inventor_city', 'patent_firstnamed_inventor_country', \n",
    "        'patent_firstnamed_inventor_id', 'patent_firstnamed_inventor_location_id',\n",
    "        'patent_firstnamed_inventor_state',\n",
    "        \n",
    "        'patent_kind', \n",
    "        # these are number of citations made by the patent - \n",
    "        # eg.  patent_num_us_patent_citations is Number of US patents cited by the selected patent\n",
    "        'patent_num_cited_by_us_patents', 'patent_num_combined_citations', \n",
    "        'patent_num_foreign_citations', 'patent_num_us_application_citations', \n",
    "        'patent_num_us_patent_citations',\n",
    "        'patent_number',\n",
    "       'patent_title', 'patent_type', 'patent_year'\n",
    "    )\n",
    "    # filter dictionary by keys\n",
    "    new1 = funcy.select_keys(lambda x: x in keys_to_keep, raw_dict)\n",
    "    # foreign prior information\n",
    "    \n",
    "    forprior_dict = filter_null_dicts(raw_dict['foreign_priority'])\n",
    "    if forprior_dict is not None:\n",
    "        new1 = process_forprior_dict(new1, forprior_dict)\n",
    "    \n",
    "    # government interest\n",
    "    gov_dict = filter_null_dicts(raw_dict['gov_interests'])\n",
    "    if gov_dict is not None:\n",
    "        new1 = process_gov_dict(new1, gov_dict)\n",
    "    \n",
    "    # application information  - no info on how app number and app id differ\n",
    "    app_dict = filter_null_dicts(raw_dict['applications'])\n",
    "    if app_dict is not None:\n",
    "        new1 = process_app_dict(new1, app_dict)\n",
    "    \n",
    "    # nber category and subcategory\n",
    "    nber_dict = filter_null_dicts(raw_dict['nbers'])\n",
    "    if nber_dict is not None:\n",
    "        new1 = process_nber_dict(new1, nber_dict)\n",
    "  \n",
    "    # assignees\n",
    "    assignee_dict = filter_null_dicts(raw_dict['assignees'])\n",
    "    if assignee_dict is not None:\n",
    "        new1 = process_assignee_dict(new1, assignee_dict) \n",
    "\n",
    "    # inventor info\n",
    "    inventor_dict = filter_null_dicts(raw_dict['inventors'])\n",
    "    if inventor_dict is not None:\n",
    "        new1 = process_inventor_dict(new1, inventor_dict) \n",
    "        \n",
    "        # lawyer info\n",
    "    lawyers_dict = filter_null_dicts(raw_dict['lawyers'])\n",
    "    if lawyers_dict is not None:\n",
    "        new1 = process_lawyers_dict(new1, lawyers_dict) \n",
    "        \n",
    "        # inventor info\n",
    "    examiners_dict = filter_null_dicts(raw_dict['examiners'])\n",
    "    if examiners_dict is not None:\n",
    "        new1 = process_examiners_dict(new1, examiners_dict) \n",
    "  \n",
    "    # citations info - these are backwards citations\n",
    "    cited_dict = filter_null_dicts(raw_dict['cited_patents'])\n",
    "    if cited_dict is not None:\n",
    "        new1 = process_cited_dict(new1, cited_dict)\n",
    "        #a bunch of patents appear to be missing citations made \n",
    "        new1['missing_citations_made'] = 0\n",
    "    else:\n",
    "        new1['missing_citations_made'] = 1\n",
    "\n",
    "#     # citing patents info\n",
    "    citing_dict = filter_null_dicts(raw_dict['citedby_patents'])\n",
    "    if citing_dict is not None:\n",
    "        new1 = process_citing_dict(new1, citing_dict)\n",
    "    return new1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cites_rank(df):\n",
    "    cites_cols = [c for c in df.columns if c.endswith('_year_cites')]\n",
    "    print(cites_cols)\n",
    "    for colname in cites_cols:\n",
    "        yr_rank_name = '{}_rank'.format(colname)\n",
    "        yr_top1_name = '{}_top1'.format(colname)\n",
    "        df[yr_rank_name] = df[colname].rank(pct=True)\n",
    "        df['{}_top1'.format(colname)] = 0\n",
    "        mask = df[yr_rank_name]>.99\n",
    "        df.loc[mask, yr_top1_name] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_long(lat_long_string, pos):\n",
    "    if pd.isnull(lat_long_string):\n",
    "        return np.nan\n",
    "    return lat_long_string.split('|')[pos]\n",
    "\n",
    "def convert_dates(x):\n",
    "    if pd.isnull(x):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        return pd.to_datetime(x, format='%Y-%m-%d').date()\n",
    "    except ValueError as e:\n",
    "        print(e, x)\n",
    "        return x\n",
    "\n",
    "def process_patent_dataframe(df):\n",
    "    '''\n",
    "    patent type -  Category of patent. There are 6 possible type:\n",
    "    \"Defensive Publication\" - 509, \"Design\" - 474736, \"Plant\" - 21052, \"Reissue\" - 16416, \n",
    "    \"Statutory Invention Registration\" - 2254, \"Utility\" - 4910906.\n",
    "    patent kind - should all be utility\n",
    "    '''\n",
    "    precompiled_cites = ['patent_num_cited_by_us_patents', 'patent_num_combined_citations', \n",
    "                         'patent_num_foreign_citations', 'patent_num_us_application_citations',\n",
    "                         'patent_num_us_patent_citations']\n",
    "\n",
    "    int_cols = ['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites',\n",
    "       '5_year_cites',  'inventor_total_num_patents',  'lawyer_total_num_assignees', 'lawyer_total_num_inventors',\n",
    "       'lawyer_total_num_patents', 'number_apps',\n",
    "       'number_assignees', 'number_assignees_sequence', 'nber_category_id', 'nber_subcategory_id',\n",
    "       'number_assistant_examiners', 'number_examiners', 'number_forprior',\n",
    "       'number_govint', 'number_inventors', 'number_inventors_sequence',\n",
    "       'number_lawyers', 'number_lawyers_sequence', 'number_nbers',\n",
    "       'number_other_examiners', 'number_primary_examiners', 'missing_citations_made', 'patent_year']\n",
    "    # create a flag for forprio\n",
    "    df['flag_has_forprior'] = df.forprior_country.apply(lambda x: int(pd.isnull(x) is not True))\n",
    "    # convert lat long into different fields\n",
    "    df['patent_firstnamed_assignee_latitude'] = df.patent_firstnamed_assignee_location_id.apply(\n",
    "        lambda x: get_lat_long(x, 0)).astype(float)\n",
    "    df['patent_firstnamed_assignee_longitude'] = df.patent_firstnamed_assignee_location_id.apply(\n",
    "        lambda x: get_lat_long(x, 1)).astype(float)\n",
    "    df['patent_firstnamed_inventor_latitude'] = df.patent_firstnamed_inventor_location_id.apply(\n",
    "        lambda x: get_lat_long(x, 0)).astype(float)\n",
    "    df['patent_firstnamed_inventor_longitude'] = df.patent_firstnamed_inventor_location_id.apply(\n",
    "        lambda x: get_lat_long(x, 1)).astype(float)\n",
    "    # convert integer columns to ints\n",
    "    df[int_cols+precompiled_cites] = df[int_cols+precompiled_cites].fillna(0).astype(int)\n",
    "    \n",
    "    # convert two date columns\n",
    "    df[[\n",
    "        'patent_date', 'forprior_date', 'app_date']]  = df[[\n",
    "            'patent_date', 'forprior_date', 'app_date']].applymap(convert_dates)\n",
    "    \n",
    "    # drop patent_firstnamed_inventor_location_id, patent_firstnamed_assignee_location_id\n",
    "    del df['patent_firstnamed_assignee_location_id']\n",
    "    del df['patent_firstnamed_inventor_location_id']\n",
    "    \n",
    "    # add some missing variables for abstract and title\n",
    "    df['missing_patent_abstract'] = df.patent_abstract.apply(pd.isnull).astype(int)\n",
    "    df['missing_patent_title'] = df.patent_title.apply(pd.isnull).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_subset_all_patents(year, df_dir=patents_dfs_dir):\n",
    "    filename = os.path.join(patents_dataset_dir, 'patents_year_{}.gz'.format(str(year)))\n",
    "    if not os.path.exists(filename):\n",
    "        print('Filename ', filename, ' does not exist')\n",
    "        return None\n",
    "    print('starting {}'.format(str(year)))\n",
    "    subset_dicts = list(map(subset_patent_dict, yield_select_patents(year, patents_dataset_dir)))\n",
    "    # check patent length\n",
    "    print(len(subset_dicts))\n",
    "    ranked_df = generate_cites_rank(pd.DataFrame(subset_dicts))\n",
    "    processed_df = process_patent_dataframe(ranked_df)  \n",
    "    df_filename = os.path.join(df_dir, 'patent_df_{}.csv'.format(str(year)))\n",
    "    print('saving to ', df_filename)\n",
    "    # saving to csv because pickle size limited \n",
    "    processed_df.to_csv(df_filename, index=False)\n",
    "    df_filename = os.path.join(df_dir, 'patent_df_{}.p'.format(str(year)))\n",
    "    write_large_pickle_file(processed_df, df_filename)\n",
    "#     return processed_df[['10_year_cites', '10_year_cites_top1', '10_year_cites_rank', \n",
    "#                         '5_year_cites', '5_year_cites_top1', '5_year_cites_rank', \n",
    "#                          'patent_number', 'patent_year', \n",
    "#                          'missing_citations_made', 'missing_patent_abstract', \n",
    "#                         'missing_patent_title']]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this kills my memory\n",
    "# pool = concurrent.futures.ProcessPoolExecutor(max_workers=6)\n",
    "\n",
    "# W = pd.concat(pool.map(fetch_subset_all_patents, range(1985, 1990)), axis=0, join='outer', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 1986\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1986.gz\n",
      "1986\n",
      "invalid literal for int() with base 10: '' \n",
      "37869\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1986.csv\n",
      "starting 1987\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1987.gz\n",
      "1987\n",
      "43189\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "time data '1984-06-00' doesn't match format specified 1984-06-00\n",
      "time data '1985-10-00' doesn't match format specified 1985-10-00\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1987.csv\n",
      "starting 1988\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1988.gz\n",
      "1988\n",
      "40212\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "time data '1986-10-00' doesn't match format specified 1986-10-00\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1988.csv\n",
      "starting 1989\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1989.gz\n",
      "1989\n",
      "49772\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1989.csv\n",
      "CPU times: user 30min 31s, sys: 15.7 s, total: 30min 47s\n",
      "Wall time: 30min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "list(map(fetch_subset_all_patents, range(1986, 1990)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 1980\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1980.gz\n",
      "1980\n",
      "invalid literal for int() with base 10: '' \n",
      "invalid literal for int() with base 10: '' \n",
      "37058\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1980.csv\n",
      "starting 1981\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1981.gz\n",
      "38916\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1981.csv\n",
      "starting 1982\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1982.gz\n",
      "1982\n",
      "invalid literal for int() with base 10: '' \n",
      "33560\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1982.csv\n",
      "starting 1983\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1983.gz\n",
      "1983\n",
      "invalid literal for int() with base 10: '' \n",
      "32588\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1983.csv\n",
      "starting 1984\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1984.gz\n",
      "1984\n",
      "38142\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "time data '1981-11-00' doesn't match format specified 1981-11-00\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1984.csv\n",
      "CPU times: user 25min 18s, sys: 11.4 s, total: 25min 29s\n",
      "Wall time: 25min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "list(map(fetch_subset_all_patents, range(1980, 1985)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 1990\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1990.gz\n",
      "1990\n",
      "42356\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1990.csv\n",
      "starting 1991\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1991.gz\n",
      "1991\n",
      "50751\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1991.csv\n",
      "starting 1992\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1992.gz\n",
      "1992\n",
      "52717\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "time data '1991-02-00' doesn't match format specified 1991-02-00\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1992.csv\n",
      "Filename  /nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1993.gz  does not exist\n",
      "starting 1994\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1994.gz\n",
      "1994\n",
      "55676\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1994.csv\n",
      "starting 1995\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1995.gz\n",
      "1995\n",
      "55387\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1995.csv\n",
      "starting 1996\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1996.gz\n",
      "1996\n",
      "60919\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1996.csv\n",
      "starting 1997\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1997.gz\n",
      "1997\n",
      "61886\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1997.csv\n",
      "starting 1998\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1998.gz\n",
      "1998\n",
      "79116\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1998.csv\n",
      "starting 1999\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1999.gz\n",
      "1999\n",
      "83626\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1999.csv\n",
      "CPU times: user 2h 8min 2s, sys: 1min 20s, total: 2h 9min 22s\n",
      "Wall time: 2h 9min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "list(map(fetch_subset_all_patents, range(1990, 2000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 1999\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_1999.gz\n",
      "1999\n",
      "83626\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_1999.csv\n",
      "starting 2000\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_2000.gz\n",
      "2000\n",
      "83783\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_2000.csv\n",
      "starting 2001\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_2001.gz\n",
      "2001\n",
      "85939\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_2001.csv\n",
      "starting 2002\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_2002.gz\n",
      "2002\n",
      "85829\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_2002.csv\n",
      "starting 2003\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_2003.gz\n",
      "2003\n",
      "85066\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_2003.csv\n",
      "starting 2004\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_2004.gz\n",
      "2004\n",
      "81969\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_2004.csv\n",
      "starting 2005\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_2005.gz\n",
      "2005\n",
      "74005\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_2005.csv\n",
      "starting 2006\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_2006.gz\n",
      "2006\n",
      "89438\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_2006.csv\n",
      "starting 2007\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_2007.gz\n",
      "2007\n",
      "78868\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_2007.csv\n",
      "starting 2008\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_2008.gz\n",
      "2008\n",
      "76893\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_2008.csv\n",
      "starting 2009\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_2009.gz\n",
      "2009\n",
      "81538\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_2009.csv\n",
      "CPU times: user 2h 45min 14s, sys: 1min 38s, total: 2h 46min 52s\n",
      "Wall time: 2h 46min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "list(map(fetch_subset_all_patents, range(1999, 2010)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 2010\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_2010.gz\n",
      "2010\n",
      "108037\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_2010.csv\n",
      "starting 2011\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_2011.gz\n",
      "2011\n",
      "90163\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_2011.csv\n",
      "starting 2012\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_2012.gz\n",
      "2012\n",
      "89919\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_2012.csv\n",
      "starting 2013\n",
      "/nobackup1/lraymond/patent_data/numerical_patents_datasets/gzips/patents_year_2013.gz\n",
      "2013\n",
      "89400\n",
      "['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites', '5_year_cites']\n",
      "saving to  /nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/patent_df_2013.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(fetch_subset_all_patents, range(2010, 2014)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#W = pd.concat(map(fetch_subset_all_patents, range(1985, 1990)), axis=0, join='outer', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # save_zipped_pickle(W, index_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
