{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Patent Random Sample\n",
    "* once I have pre processed all the patents in the sample, create an index file listing those with missing info\n",
    "* this is what the random sample will come from\n",
    "* then, I need to upload the claims code to engaging so it can be easily run for all patents in the random sample\n",
    "* Once that is completed, I will generate a random sample of those patents \n",
    "* I need to update the description and references code to add an append option - so I don't duplicate work\n",
    "* then, I can do a basic classifier\n",
    "\n",
    "* On the sloan partition, I also need to test the threading and multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent\n",
    "import pickle\n",
    "import json\n",
    "import funcy\n",
    "import csv\n",
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imblearn\n",
    "\n",
    "import sklearn\n",
    "# from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# #from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "# from imblearn.metrics import classification_report_imbalanced\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split description directory\n",
    "index_file = '/pool001/lraymond/patent_data/index_files/pat_nums_index.csv'\n",
    "PATENTS_PICKLE_DIR = '/nobackup1/lraymond/patent_data/numerical_patents_datasets/dataframes/stored_pickles'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_patent_number(patent_num):\n",
    "    '''try to convert patent number to int, flag errors'''\n",
    "    try:\n",
    "        t = int(patent_num)\n",
    "        return True\n",
    "    except (TypeError, ValueError):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_patents(filename, patents_pickle_dir=PATENTS_PICKLE_DIR):\n",
    "    df = pd.read_pickle(os.path.join(patents_pickle_dir, filename))\n",
    "    df2 = df[['10_year_cites', '15_year_cites', '20_year_cites', '30_year_cites',\n",
    "       '5_year_cites', 'assignee_is_company', 'assignee_is_gov',\n",
    "       'assignee_is_ind', 'forprior_country',\n",
    "       'forprior_date', \n",
    "       'inventor_total_num_patents', 'lawyer_organization',\n",
    "       'lawyer_total_num_assignees', 'lawyer_total_num_inventors',\n",
    "       'lawyer_total_num_patents', \n",
    "       'nber_category_id',  'nber_subcategory_id',\n",
    "        'number_apps', 'number_assignees',\n",
    "        'number_assistant_examiners',\n",
    "       'number_examiners', 'number_forprior', 'number_govint',\n",
    "       'number_inventors',  'number_lawyers',\n",
    "       'number_primary_examiners', 'patent_abstract', 'patent_date',\n",
    "      'patent_firstnamed_assignee_country',\n",
    "        'patent_firstnamed_assignee_state',\n",
    "        'patent_firstnamed_inventor_country',\n",
    "        'patent_firstnamed_inventor_state',\n",
    "        'patent_num_cited_by_us_patents',\n",
    "       'patent_num_combined_citations', 'patent_num_foreign_citations',\n",
    "       'patent_num_us_application_citations', 'patent_num_us_patent_citations',\n",
    "       'patent_number', 'patent_title',  'patent_year',\n",
    "       '10_year_cites_rank', '10_year_cites_top1', '15_year_cites_rank',\n",
    "       '15_year_cites_top1', '20_year_cites_rank', '20_year_cites_top1',\n",
    "       '30_year_cites_rank', '30_year_cites_top1', '5_year_cites_rank',\n",
    "       '5_year_cites_top1', 'flag_has_forprior',\n",
    "       'patent_firstnamed_assignee_latitude',\n",
    "       'patent_firstnamed_assignee_longitude',\n",
    "       'patent_firstnamed_inventor_latitude',\n",
    "       'patent_firstnamed_inventor_longitude', \n",
    "        'missing_citations_made', 'missing_patent_abstract',\n",
    "       'missing_patent_title']].sort_values('patent_number').drop_duplicates('patent_number')\n",
    "    df2['is_valid_patent_number'] = df2.patent_number.apply(is_valid_patent_number)\n",
    "    # currently using only patents with abstract, title and citations\n",
    "    mask = (\n",
    "        (df2.missing_citations_made==0) &(\n",
    "                df2.missing_patent_abstract==0) & (\n",
    "                    df2.missing_patent_abstract==0) & (df2.is_valid_patent_number==1))\n",
    "    return df2[mask]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open up the patent dataframes from each year, create an index file with those with citations made, \n",
    "txt_files = sorted([f for f in os.listdir(\n",
    "    patents_pickle_dir) if os.path.isfile(os.path.join(patents_pickle_dir, f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_patents = pd.concat(list(map(subset_patents, txt_files)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_patents2 = valid_patents.sort_values(['patent_number', 'patent_year']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1994958, 59)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_patents2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_patents2[['assignee_is_company', 'assignee_is_gov',\n",
    "       'assignee_is_ind',]] = valid_patents2[['assignee_is_company', 'assignee_is_gov',\n",
    "       'assignee_is_ind',]].fillna(0).astype(int, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_assignee_is_ind(val):\n",
    "    if pd.isnull(val):\n",
    "        return np.nan\n",
    "    if isinstance(val, str):\n",
    "        return int(val=='True')\n",
    "    try:\n",
    "        return int(val)\n",
    "    except ValueError:\n",
    "        print(val)\n",
    "        return 0\n",
    "        \n",
    "\n",
    "valid_patents2['assignee_is_ind'] = valid_patents2['assignee_is_ind'].apply(convert_assignee_is_ind)\n",
    "\n",
    "valid_patents2.to_csv(index_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/software/sloan/local/lib/py36/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "valid_patents2 = pd.read_csv(index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_patents2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
